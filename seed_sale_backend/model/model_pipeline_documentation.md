# Model Pipeline Documentation

## Overview

This code implements a comprehensive machine learning pipeline for predicting agricultural product units (UNITS) based on various features like product characteristics, sales year, lifecycle stage, and resistance traits. The pipeline includes data sourcing, data preprocessing, feature engineering, model training with hyperparameter tuning, and evaluation capabilities.

## Architecture

The code follows an object-oriented design with separate classes handling different aspects of the machine learning workflow:

## Classes Description

### 1. `DataSourcing`
**Purpose**: Handles data loading from CSV files.

**Key Methods**:
- `__init__(file_path='case_study_data.csv')`: Initialize with file path
- `read_data_local()`: Read CSV data into pandas DataFrame

**Usage**:
```python
data_sourcer = DataSourcing('case_study_data.csv')
df = data_sourcer.read_data_local()
```

### 2. `DataPreprocessing`
**Purpose**: Handles data cleaning and preprocessing operations.

**Key Methods**:
- `handle_duplicates()`: Remove duplicate rows
- `handle_missing_val()`: Handle missing values by dropping rows with NaN
- `handle_aggregations()`: Aggregate data by grouping non-target columns and summing UNITS
- `handle_outlier()`: Remove outliers using IQR method
- `remove_lifecycle_violations()`: Ensure lifecycle progression is logical (currently commented out)
- `preprocessing_fit()`: Complete preprocessing pipeline for training data
- `preprocessing_score()`: Minimal preprocessing for scoring data

**Usage**:
```python
preprocessor = DataPreprocessing(df)
clean_df = preprocessor.preprocessing_fit()
```

### 3. `FeatureEngineering`
**Purpose**: Creates new features from existing data to improve model performance.

**Key Methods**:
- `feature_engineering(df)`: Creates multiple types of features:
  - **Date-based features**: `PRODUCT_AGE`, `YEARS_SINCE_FIRST_SALE`
  - **Interaction features**: `RESISTANCE_SUM`, `RESISTANCE_DIFF`
  - **Ratio features**: `TRAIT_SCORE_PER_MATURITY`
  - **Polynomial features**: `PLANT_HEIGHT_SQ`, `PLANT_HEIGHT_CUBE`
  - **Categorical combinations**: `PRODUCT_STATE`
  - **Aggregation features**: `PRODUCT_COUNT`, `STATE_AVG_PLANT_HEIGHT`

**Usage**:
```python
feature_eng = FeatureEngineering()
enhanced_df = feature_eng.feature_engineering(df)
```


### 4. `Training`
**Purpose**: Handles model training with hyperparameter tuning using GridSearchCV.

**Key Methods**:
- `tune_model_with_gridsearch(model_class, param_grid)`: Tune single model
- `tune_multiple_models_with_gridsearch(model_param_list)`: Compare multiple models

**Features**:
- Supports both TargetEncoder and OrdinalEncoder for categorical variables
- Uses ColumnTransformer for preprocessing
- Automatically handles models with/without random_state parameter
- Returns comprehensive results including CV scores and test performance

**Usage**:
```python
trainer = Training(X_train, y_train, X_test, y_test, cat_cols)
best_result = trainer.tune_multiple_models_with_gridsearch(model_param_list)
```

### 5. `GetBestModel`
**Purpose**: Orchestrates the model selection process.

**Key Methods**:
- `train_test_split_data()`: Split data into training and testing sets
- `get_encoding_col()`: Determine categorical columns for encoding
- `get_best_model()`: Train and compare multiple models to find the best one

**Supported Models**:
- RandomForestRegressor
- Lasso Regression
- Ridge Regression
- SimpleNNRegressor (custom neural network)

**Usage**:
```python
model_selector = GetBestModel(df)
best_model = model_selector.get_best_model()
```

### 6. `ModelPipeline`
**Purpose**: Main orchestrator class that coordinates the entire ML pipeline.

**Key Methods**:
- `fit()`: Complete training pipeline (data sourcing → preprocessing → feature engineering → model training)
- `score()`: Evaluation pipeline for new data


### 7. `SimpleNNRegressor`
**Purpose**: Custom neural network regressor compatible with scikit-learn.

**Key Methods**:
- `__init__(input_dim, hidden_dim, lr, epochs, batch_size)`: Initialize NN parameters
- `fit(X, y)`: Train the neural network
- `predict(X)`: Make predictions
- `_to_tensor(data)`: Convert data to PyTorch tensors

**Usage**:
```python
nn_model = SimpleNNRegressor(hidden_dim=64, lr=0.001, epochs=20)
nn_model.fit(X_train, y_train)
predictions = nn_model.predict(X_test)
```

**Usage**:
```python
pipeline = ModelPipeline()
best_model = pipeline.fit()
predictions = pipeline.score()
```

## How to Run

### Prerequisites
```bash
- Create virtual environment with Python version >= 3.9
- Run pip install -r requirements.txt 
```

### Required Data Files
- `case_study_data.csv`: Training data
- `synthetic_test_data.csv`: Test data for evaluation (Generated by the author)

### Basic Usage

#### 1. Complete Pipeline Execution
```python
- Under current folder, run python main.py
```


## Expected Output

The pipeline will output:
- Data preprocessing statistics (duplicates removed, missing values handled)
- Feature engineering completion confirmation
- Model training progress with GridSearchCV results
- Best model selection with performance metrics:
  - Best CV R² Score
  - Test R² Score  
  - Test RMSE
- Final predictions on test data
  - e.g. "Pipeline completed successfully!
Final predictions: [2.07235947 1.8712158  1.97178764 1.77064397 2.07235947 1.80705169 1.77064397 4.66509969 1.45392665 1.97178764]"

## Key Features

1. **Automated Pipeline**: End-to-end automation from raw data to predictions
2. **Multiple Model Support**: Compares Random Forest, Lasso, Ridge, and Neural Network
3. **Proper Data Handling**: Prevents data leakage through proper train/test splitting
4. **Feature Engineering**: Comprehensive feature creation including interactions and aggregations
5. **Hyperparameter Tuning**: Grid search with cross-validation for optimal parameters
6. **Categorical Encoding**: Supports both target encoding and ordinal encoding
7. **Extensible Design**: Easy to add new models or preprocessing steps

## Data Requirements

The input data should contain columns like:
- `PRODUCT`: Product identifier
- `SALESYEAR`: Year of sales
- `LIFECYCLE`: Product lifecycle stage
- `STATE`: Geographic state
- `RELEASE_YEAR`: Product release year
- Various resistance and trait columns
- `UNITS`: Target variable (what we're predicting)

## Performance Considerations

- The pipeline uses cross-validation which can be computationally expensive
- Feature engineering creates many new features which may increase memory usage
- GridSearchCV with multiple models can take significant time to complete